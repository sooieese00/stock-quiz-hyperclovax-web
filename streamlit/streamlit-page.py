import streamlit as st
import requests
from bs4 import BeautifulSoup
import time
import json
import re

# CompletionExecutor í´ë˜ìŠ¤: API í˜¸ì¶œ
class CompletionExecutor:
    def __init__(self, host, api_key, api_key_primary_val, request_id):
        self._host = host
        self._api_key = api_key
        self._api_key_primary_val = api_key_primary_val
        self._request_id = request_id

    def execute(self, completion_request):
        headers = {
            'X-NCP-CLOVASTUDIO-API-KEY': self._api_key,
            'X-NCP-APIGW-API-KEY': self._api_key_primary_val,
            'X-NCP-CLOVASTUDIO-REQUEST-ID': self._request_id,
            'Content-Type': 'application/json; charset=utf-8',
            'Accept': 'text/event-stream'
        }

        with requests.post(self._host + '/testapp/v1/tasks/iqsmk52h/chat-completions',
                           headers=headers, json=completion_request, stream=True) as r:
            event_stream_data = []
            for line in r.iter_lines():
                if line:
                    event_stream_data.append(line.decode("utf-8"))
            return event_stream_data

#ë„¤ì´ë²„ ë‰´ìŠ¤ë¥¼ ê²€ìƒ‰í•´ í¬ë¡¤ë§
def get_search_results(keyword):
    response = requests.get(
        #ê´€ë ¨ë„ìˆœ, 24ì‹œê°„ ì´ë‚´ì˜ ë‰´ìŠ¤ ìˆ˜ì§‘
        f"https://search.naver.com/search.naver?where=news&sm=tab_jum&query={keyword}&sort=0&pd=1d")
    html = response.text
    soup = BeautifulSoup(html, "html.parser")
    return soup.select("div.info_group")

# ê°œë³„ ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ í¬ë¡¤ë§
def get_article_details(url):
    response = requests.get(url, headers={'User-agent': 'Mozilla/5.0'})
    html = response.text
    soup = BeautifulSoup(html, "html.parser")
    #ë‰´ìŠ¤ íƒ€ì…ë§ˆë‹¤ êµ¬ì¡°ê°€ ë‹¤ë¦„. ë‰´ìŠ¤ íƒ€ì…ì— ë”°ë¼ ë‹¤ë¥¸ ë°©ì‹ìœ¼ë¡œ ë³¸ë¬¸ì„ ê°€ì ¸ì˜´
    if "entertain" in response.url:
        title = soup.select_one(".end_tit")
        content = soup.select_one("#articeBody")
    elif "sports" in response.url:
        title = soup.select_one("h4.title")
        content = soup.select_one("#newsEndContents")
        divs = content.select("div")
        for div in divs:
            div.decompose()
        paragraphs = content.select("p")
        for p in paragraphs:
            p.decompose()
    else:
        title = soup.select_one(".media_end_head_headline")
        content = soup.select_one("#dic_area")

    return title.text.strip(), content.text.strip()

# ë‰´ìŠ¤ ë°ì´í„°ë¥¼ ìˆ˜ì§‘
def collect_news_data(keyword):
    articles = get_search_results(keyword) #ë‰´ìŠ¤ ê²€ìƒ‰ í•¨ìˆ˜ í˜¸ì¶œ
    titles = []
    contents = []
    links = []

    for i, article in enumerate(articles):
        if i >= 3: #ìµœëŒ€ 3ê°œì˜ ê¸°ì‚¬ë§Œ ìˆ˜ì§‘
            break
        links_in_article = article.select("a.info")
        #ì œëª©, ë³¸ë¬¸, ë§í¬ ì¶”ì¶œ
        if len(links_in_article) >= 2:
            url = links_in_article[1].attrs["href"]
            title, content = get_article_details(url)#ê°œë³„ ë‰´ìŠ¤ê¸°ì‚¬ ìˆ˜ì§‘ í•¨ìˆ˜ í˜¸ì¶œ
            titles.append(title)
            contents.append(content)
            links.append(url)
            time.sleep(0.3)# ìš”ì²­ ê°„ê²©ì„ ë‘ì–´ ì„œë²„ ê³¼ë¶€í•˜ ë°©ì§€

    return titles, contents, links

# ëª¨ë¸ì˜ ì‘ë‹µ ë°ì´í„° ìŠ¤íŠ¸ë¦¼ì—ì„œ ë§ˆì§€ë§‰ ë©”ì‹œì§€ ë‚´ìš©ì„ ì¶”ì¶œ
def parse_event_stream(stream):
    last_message_content = None
    for line in stream:
        if line.startswith("data:"):
            data = json.loads(line[len("data:"):])
            if "message" in data and "content" in data["message"]:
                last_message_content = data["message"]["content"]
    return last_message_content

# ì‘ë‹µë°›ì€ í€´ì¦ˆë¥¼ ë¶€ë¶„ë³„ë¡œ ë‚˜ëˆ  ì €ì¥. í˜ì´ì§€ì—ì„œ ìˆœì°¨ì ìœ¼ë¡œ ì¶œë ¥í•˜ê¸° ìœ„í•¨
def parse_response(data):
    lines = data.split('\n')
    parsed_data = {
        "ì˜¤ëŠ˜ì˜ ì§ˆë¬¸": "",
        "1": "",
        "2": "",
        "3": "",
        "4": "",
        "ì •ë‹µ": "",
        "í•´ì„¤": ""
    }
    for line in lines:
        if line.startswith("ì˜¤ëŠ˜ì˜ ì§ˆë¬¸"):
            parsed_data["ì˜¤ëŠ˜ì˜ ì§ˆë¬¸"] = line
        elif line.startswith("1."):
            parsed_data["1"] = line
        elif line.startswith("2."):
            parsed_data["2"] = line
        elif line.startswith("3."):
            parsed_data["3"] = line
        elif line.startswith("4."):
            parsed_data["4"] = line
        elif line.startswith("ì •ë‹µ"):
            parsed_data["ì •ë‹µ"] = line
        elif line.startswith("í•´ì„¤"):
            parsed_data["í•´ì„¤"] = line
    return parsed_data

# ì •ë‹µ ë²ˆí˜¸ë¥¼ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜. ì‚¬ìš©ì ì„ íƒê°’ì˜ ì •ë‹µ ìœ ë¬´ë¥¼ íŒë‹¨í•˜ê¸° ìœ„í•¨
def extract_answer_number(answer_text):
    match = re.search(r'ì •ë‹µ\s*:\s*(\d)', answer_text)
    return match.group(1) if match else None

# Streamlit ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜
def main():
    st.title("ì£¼ì‹ í€´ì¦ˆ ìƒì„±ê¸°")

    # ì‚¬ìš©ì ì…ë ¥ ì„¹ì…˜
    col1, col2, col3, col4 = st.columns([1, 1, 1, 1])
    with col1:
        blank = []
    with col2:
        age = st.number_input("íˆ¬ìì ë‚˜ì´:", min_value=0, max_value=120, value=25)
    with col3:
        year = st.number_input("íˆ¬ìê²½ë ¥(ë…„):", min_value=0, max_value=100, value=1)
    with col4:
        blank = []
    keyword = st.text_input("ë³´ìœ  ì¢…ëª©:", value="", placeholder="ë³´ìœ  ì¢…ëª©ì„ ì…ë ¥í•˜ì„¸ìš”",
                            key='keyword_input', label_visibility="collapsed")
    
    titles = []
    links =[]

    #ë‰´ìŠ¤ í¬ë¡¤ë§ í•¨ìˆ˜ í˜¸ì¶œ
    if keyword and 'quiz_data' not in st.session_state:
        with st.spinner('ë‰´ìŠ¤ ì½ëŠ”ì¤‘..ğŸ“°'):
            titles, contents, links = collect_news_data(keyword)
            #í¬ë¡¤ë§ ì™„ë£Œ í™•ì¸ ìœ„í•´ ë‰´ìŠ¤ ì œëª© ì¶œë ¥
            if contents:
                articles_content = " ".join(contents)
                st.success("ìˆ˜ì§‘ëœ ë‰´ìŠ¤ ì œëª©")
                for i in titles:
                    st.write(i)

                #ëª¨ë¸ì— ì „ë‹¬í•  í”„ë¡¬í”„íŠ¸ ì •ì˜. ì‚¬ìš©ì ì…ë ¥ê°’ê³¼ í¬ë¡¤ë§í•œ ë‰´ìŠ¤ ë°ì´í„° í¬í•¨
                preset_text = [
                    {
                        "role": "system",
                        "content": (
                            "ë„ˆëŠ” ì‚¬ìš©ìê°€ ì£¼ëŠ” ìµœì‹  ë‰´ìŠ¤ ê¸°ì‚¬ì˜ ë‚´ìš©ì„ ì·¨í•©í•´ ì‚¬ìš©ìì—ê²Œ ì£¼ì‹ íˆ¬ì êµìœ¡ ì œê³µì„ ëª©ì ìœ¼ë¡œ í€´ì¦ˆë¥¼ ë§Œë“¤ì–´ì¤„ê±°ì•¼."
                            "\ní€´ì¦ˆëŠ” ì‚¬ìš©ìê°€ ì£¼ëŠ” ìµœì‹ ê¸°ì‚¬ ë‚´ìš©ì—ì„œ ì£¼ì‹ ê°€ê²©ì— ì˜í–¥ì„ ì¤„ ì •ë³´ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ, ì‚¬ìš©ìì˜ ë³´ìœ ì¢…ëª©ì— ê´€í•´ì„œ ë‚´ì¤˜."
                            "\n4ì§€ì„ ë‹¤ì— ì •ë‹µì€ 1ê°œì¸ í€´ì¦ˆì´ê³ , ë”± 1ê°œì˜ í€´ì¦ˆë§Œ ë§Œë“¤ë©´ ë¼."
                            "\nì•„ë˜ì— ë„ˆê°€ í•´ì•¼í•˜ëŠ” ë‹µë³€ì˜ í˜•ì‹ì„ ì§€ì •í•´ì¤„ê²Œ. ì—¬ê¸° ~~~ë¶€ë¶„ì— ë„ˆì˜ ë‹µë³€ì„ ë„£ì–´ì£¼ë©´ ë¼."
                            "\n\n[ë‹µë³€ í˜•ì‹]\nì˜¤ëŠ˜ì˜ ì§ˆë¬¸ :~~~? \n1.~~~\n2.~~~\n3.~~~\n4.~~~\n\nì •ë‹µ :~~~ë²ˆ ~~~\n\ní•´ì„¤ :~~~"
                        )
                    },
                    {
                        "role": "user",
                        "content": f"{articles_content}\në‚˜ì´: {age}ì„¸\níˆ¬ìê²½ë ¥: {year}ë…„\në³´ìœ ì¢…ëª©: {keyword}"
                    }
                ]

                request_data = {
                    'messages': preset_text,
                    'topP': 0.8,
                    'topK': 0,
                    'maxTokens': 256,
                    'temperature': 0.5,
                    'repeatPenalty': 5.0,
                    'stopBefore': [],
                    'includeAiFilters': True,
                    'seed': 0
                }

                #íŠœë‹ ëª¨ë¸ API í˜¸ì¶œ
                completion_executor = CompletionExecutor(
                    host='https://clovastudio.stream.ntruss.com',
                    api_key='NTA0MjU2MWZlZTcxNDJiY45r/DkTDk7oBmqKVrH2tgppYRF/3kCtv0bwtT7ihqUM',
                    api_key_primary_val='2vb3PzZVsMZcjwGY1yQG7xbuK0FqU7hrFGli34ou',
                    request_id='76902a7a-2232-400c-843f-65a8edfc8e46'
                )

                #ëª¨ë¸ì˜ ì‘ë‹µ ê²°ê³¼ ìˆ˜ì‹  í™•ì¸
                with st.spinner('í€´ì¦ˆ ìƒì„±ì¤‘..ğŸ§'):
                    event_stream_data = completion_executor.execute(request_data)
                    response = parse_event_stream(event_stream_data)
                    st.success("í€´ì¦ˆ ìƒì„±ì™„ë£Œâœ”")
                    parsed_response = parse_response(response)
                    st.session_state.quiz_data = parsed_response
    
    #ëª¨ë¸ì˜ ì‘ë‹µ í€´ì¦ˆì—ì„œ ì§ˆë¬¸ê³¼ ì„ ì§€ë§Œ ì¶œë ¥
    if 'quiz_data' in st.session_state:
        parsed_response = st.session_state.quiz_data
        #ëª¨ë¸ì˜ ì‘ë‹µ í€´ì¦ˆë¥¼ ë¶€ë¶„ë³„ë¡œ ë‚˜ëˆ„ì–´ ì €ì¥í•˜ëŠ” í•¨ìˆ˜ í˜¸ì¶œ
        question, numberOne, numberTwo, numberThree, numberFour, answer, description = list(parsed_response.keys())[:7]
        st.write(parsed_response[question])

        # ì‚¬ìš©ì ì„ íƒ ì´ˆê¸°í™”
        if 'user_choice' not in st.session_state:
            st.session_state.user_choice = None

        choice = st.radio("ë‹µì„ ì„ íƒí•˜ì„¸ìš”", 
                          (parsed_response[numberOne], 
                           parsed_response[numberTwo], 
                           parsed_response[numberThree], 
                           parsed_response[numberFour]))

        if st.button("ì œì¶œ"):
            st.session_state.user_choice = choice

        #ì •ë‹µì—¬ë¶€ ì²´í¬
        if st.session_state.user_choice:
            user_choice = st.session_state.user_choice
            answer_number = extract_answer_number(parsed_response[answer])
            selected_number = user_choice.split('.')[0]
        
            if selected_number == answer_number:
                st.success("ì •ë‹µì…ë‹ˆë‹¤!")
            else:
                st.error("ì˜¤ë‹µì…ë‹ˆë‹¤!")

            #ì •ë‹µê³¼ í•´ì„¤ ì¶œë ¥
            st.write(parsed_response[answer])
            st.write(parsed_response[description])
            

if __name__ == "__main__":
    main()
